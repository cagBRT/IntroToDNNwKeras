{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPPpK/yBwgwtZUp24A5HqMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/IntroToDNNwKeras/blob/master/Creating_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating DNN Models"
      ],
      "metadata": {
        "id": "dzFsn9fkPF5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we create examples of the following DNN models: <br>\n",
        ">Simple Seq Model<br>\n",
        "A model using the Functional Model API<br>\n",
        "MultiLayer Perceptron Binary Classification<br>\n",
        "MLP for Multiclass Classification<br>\n",
        "MLP for Regression<br>\n",
        "Convolutional Neural Network<br>\n",
        "Recurrent Neural Network<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "t0jMwrt1PIey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "AYsf1lTJDvdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1rVIXYYEgwO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/IntroToDNNwKeras.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "metadata": {
        "id": "deDEcmR_HTAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Sequential Model<br>\n",
        "Using \"add\" to create layers"
      ],
      "metadata": {
        "id": "amCNJxLD4j-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of a model defined with the sequential api\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# define the model\n",
        "model_seq = Sequential()\n",
        "model_seq.add(Dense(100, input_shape=(8,)))\n",
        "model_seq.add(Dense(80))\n",
        "model_seq.add(Dense(30))\n",
        "model_seq.add(Dense(10))\n",
        "model_seq.add(Dense(5))\n",
        "model_seq.add(Dense(1))"
      ],
      "metadata": {
        "id": "OIb-qqlT4n-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq.summary()"
      ],
      "metadata": {
        "id": "eoJkyzuP5p6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model_seq, \"model_seq.png\")"
      ],
      "metadata": {
        "id": "TUlEznBY5wfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the model\n",
        "plot_model(model_seq, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "X1FOZkA-DbBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional Model API<br>\n",
        "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "wmLR_EJe4z3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "N0GtGxPOEPcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of a model defined with the functional api\n",
        "# define the layers\n",
        "x_in = Input(shape=(8,))\n",
        "x = Dense(10)(x_in)\n",
        "x_out = Dense(1)(x)"
      ],
      "metadata": {
        "id": "oHpZi2_D45uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, you can create a Model by specifying its inputs and outputs in the graph of layers"
      ],
      "metadata": {
        "id": "N2X-YhGtQXdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model_complex = Model(inputs=x_in, outputs=x_out)"
      ],
      "metadata": {
        "id": "_qbfbZNXQRsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_complex.summary()"
      ],
      "metadata": {
        "id": "hTW9_ch85gyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model_complex, \"model_complex.png\")"
      ],
      "metadata": {
        "id": "4WWrKwzn5971"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the model\n",
        "plot_model(model_complex, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "fmTjKlbjD5sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "geY4hao58dDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiLayer Perceptron Binary Classification"
      ],
      "metadata": {
        "id": "Sja_PODk6Srz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp for binary classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "F9UTaQQ56eaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Dataset**<br>\n",
        "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
        "<br>\n",
        "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal."
      ],
      "metadata": {
        "id": "ijnHjI7L8L2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- All 34 are continuous<br>\n",
        "-- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. <br>\n",
        "This is a binary classification task."
      ],
      "metadata": {
        "id": "HlqITgBu8PNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
        "df = read_csv(path, header=None)"
      ],
      "metadata": {
        "id": "lu7XyCs07umx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "z4Ym1jGk7v_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]"
      ],
      "metadata": {
        "id": "yBqyLCxQ6iMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_bc = Sequential()\n",
        "model_bc.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model_bc.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model_bc.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "TXUdfxHu6V9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bc.summary()"
      ],
      "metadata": {
        "id": "ybyUf0fq7KLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model_bc, \"model_bc.png\")"
      ],
      "metadata": {
        "id": "hwG9zfLg7TH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the model\n",
        "plot_model(model_bc, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "WEfZkIR2EXz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model_bc.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# train the model\n",
        "history= model_bc.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0,validation_split=0.3)"
      ],
      "metadata": {
        "id": "xDaz9x0Y7NFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "loss, acc = model_bc.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "id": "i9ysX_U56p4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = model_bc.predict([row])\n",
        "print('Predicted: %.3f' % yhat)"
      ],
      "metadata": {
        "id": "Dxt4a2qK6rsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "X9s8st2bHktk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP Binary Classification Model created using the Model API"
      ],
      "metadata": {
        "id": "58hhHeOXSxdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=keras.Input(shape=(34))\n",
        "inputs.dtype"
      ],
      "metadata": {
        "id": "RXviq18wRN8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_bc.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model_bc.add(Dense(8, activation='relu', kernel_initializer='he_normal'))"
      ],
      "metadata": {
        "id": "_121oViPRpUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "JzGC-Z2mR1U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense=layers.Dense(10, activation='relu')\n",
        "x=dense(inputs)\n",
        "x=layers.Dense(8, activation='relu')(x)\n",
        "outputs=layers.Dense(1)(x)"
      ],
      "metadata": {
        "id": "E3vVfaWmRkWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mlp_bc\")"
      ],
      "metadata": {
        "id": "nffwdST1R8cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "CrOLsJT8SndM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model_bc, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "LJG_MLYVSsh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP for Multiclass Classification"
      ],
      "metadata": {
        "id": "Os5rJuKn8iVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "4Lmh4TWj8t0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n",
        "df = read_csv(path, header=None)"
      ],
      "metadata": {
        "id": "gQZIyl_H8vto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "1MHssuv19knI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]"
      ],
      "metadata": {
        "id": "oBWzXva18yz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_mc = Sequential()\n",
        "model_mc.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model_mc.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model_mc.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "oDMYQ53h81DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mc.summary()"
      ],
      "metadata": {
        "id": "hEpUWuZc-YsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model_mc, \"model_mc.png\")"
      ],
      "metadata": {
        "id": "vi8IzX6E-VdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the model\n",
        "plot_model(model_mc, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "19BfHSbhEgZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model_mc.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit the model\n",
        "history=model_mc.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0, validation_split=0.3)\n",
        "# evaluate the model\n",
        "loss, acc = model_mc.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "id": "5RtRs7yw83ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "row = [5.1,3.5,1.4,0.2]\n",
        "yhat = model_mc.predict([row])\n",
        "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"
      ],
      "metadata": {
        "id": "a0Xi0k8b8mSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "15y0rKluHrmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP for Regression"
      ],
      "metadata": {
        "id": "mzABiqeT9xKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp for regression\n",
        "from numpy import sqrt\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "TVnHpv2r94jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(path, header=None)"
      ],
      "metadata": {
        "id": "co6-8H9S97Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    1. CRIM      per capita crime rate by town\n",
        "    2. ZN        proportion of residential land zoned for lots over \n",
        "                 25,000 sq.ft.\n",
        "    3. INDUS     proportion of non-retail business acres per town\n",
        "    4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
        "                 river; 0 otherwise)\n",
        "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
        "    6. RM        average number of rooms per dwelling\n",
        "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
        "    8. DIS       weighted distances to five Boston employment centres\n",
        "    9. RAD       index of accessibility to radial highways\n",
        "    10. TAX      full-value property-tax rate per $10,000\n",
        "    11. PTRATIO  pupil-teacher ratio by town\n",
        "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
        "                 by town\n",
        "    13. LSTAT    % lower status of the population\n",
        "    14. MEDV     Median value of owner-occupied homes in $1000's"
      ],
      "metadata": {
        "id": "J73AqmEZ-DvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "rIPikAvO98E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]"
      ],
      "metadata": {
        "id": "TQQcP4pa-Kn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_lr = Sequential()\n",
        "model_lr.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model_lr.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model_lr.add(Dense(1))\n",
        "# compile the model\n",
        "model_lr.compile(optimizer='adam', loss='mse')\n",
        "# fit the model\n",
        "history=model_lr.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0, validation_split=0.3)"
      ],
      "metadata": {
        "id": "uwJgvcwU-Otr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr.summary()"
      ],
      "metadata": {
        "id": "TY0SC9sj-jKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model_lr, \"model_lr.png\")"
      ],
      "metadata": {
        "id": "PoNFdS4z-vwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the model\n",
        "plot_model(model_lr, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "FiZ78o0pEpCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "error = model_lr.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))"
      ],
      "metadata": {
        "id": "MRBza1lE9zhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
        "yhat = model_lr.predict([row])\n",
        "print('Predicted: %.3f' % yhat)"
      ],
      "metadata": {
        "id": "2NJVxHh9-3Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "awOMlYBSHvNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks(CNNs)"
      ],
      "metadata": {
        "id": "7wv1EXT__Ans"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of a cnn for image classification\n",
        "from numpy import asarray\n",
        "from numpy import unique\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "kLtN3PMz_qY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading and plotting the mnist dataset\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "BjcfF_r6_J1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (x_train.shape,y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "# plot first few images\n",
        "for i in range(25):\n",
        " # define subplot\n",
        " pyplot.subplot(5, 5, i+1)\n",
        " # plot raw pixel data\n",
        " pyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "RdGCQEAC_FOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape data to have a single channel\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
        "# determine the shape of the input images\n",
        "in_shape = x_train.shape[1:]\n",
        "# determine the number of classes\n",
        "n_classes = len(unique(y_train))\n",
        "print(in_shape, n_classes)"
      ],
      "metadata": {
        "id": "MGf6ClP1_1mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize pixel values\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "vQDsIaqQ_35i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=in_shape))\n",
        "model_cnn.add(MaxPool2D((2, 2)))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(Dense(n_classes, activation='softmax'))\n",
        "# define loss and optimizer\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xrGzheq7_6_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.summary()"
      ],
      "metadata": {
        "id": "2WJywQtDAKB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model_cnn, \"model_cnn.png\")"
      ],
      "metadata": {
        "id": "66l4P8_EAMT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the model\n",
        "plot_model(model_cnn, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "caiu6nUvE-Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "history=model_cnn.fit(x_train, y_train, epochs=10, batch_size=128, verbose=0, validation_split=0.3)"
      ],
      "metadata": {
        "id": "zgfxL92PAijx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "loss, acc = model_cnn.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "id": "8WeQrrmG_beJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "image = x_train[0]\n",
        "yhat = model_cnn.predict(asarray([image]))\n",
        "print('Predicted: class=%d' % argmax(yhat))"
      ],
      "metadata": {
        "id": "ZgD0VBWv_-dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "hOTBsFFkH0J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks"
      ],
      "metadata": {
        "id": "qkCsVayBAv3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the sequence is 1,2,3,4,5,6,7,8,9,10<br>\n",
        "The input and output samples for training the model\n",
        "\n",
        "1,2,3,4,  5 6 <br>\n",
        "2,3,4,5,  6 7<br>\n",
        "3,4,5,6,  7 8<br>\n",
        "..."
      ],
      "metadata": {
        "id": "pNjPXeDDCyUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm for time series forecasting\n",
        "from numpy import sqrt\n",
        "from numpy import asarray\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "metadata": {
        "id": "iVkG3oTQBNRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        " X, y = list(), list()\n",
        " for i in range(len(sequence)):\n",
        "  # find the end of this pattern\n",
        "  end_ix = i + n_steps\n",
        "  # check if we are beyond the sequence\n",
        "  if end_ix > len(sequence)-1:\n",
        "    break\n",
        "  # gather input and output parts of the pattern\n",
        "  seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "  X.append(seq_x)\n",
        "  y.append(seq_y)\n",
        " return asarray(X), asarray(y)"
      ],
      "metadata": {
        "id": "i_t4r9DZBElk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n",
        "df = read_csv(path, header=0, index_col=0).squeeze(\"columns\")\n",
        "# retrieve the values\n",
        "values = df.values.astype('float32')"
      ],
      "metadata": {
        "id": "If3H3oZNBw6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the window size\n",
        "n_steps = 5\n",
        "# split into samples\n",
        "X, y = split_sequence(values, n_steps)\n",
        "# reshape into [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "# split into train/test\n",
        "n_test = 12\n",
        "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "iElLH0TSB81Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\n",
        "model_rnn.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
        "model_rnn.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
        "model_rnn.add(Dense(1))"
      ],
      "metadata": {
        "id": "3Okd9CpvA9m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn.summary()"
      ],
      "metadata": {
        "id": "ApOWdMvWCddG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model_rnn, \"model_rnn.png\")"
      ],
      "metadata": {
        "id": "cU8_3vBoCiQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the model\n",
        "plot_model(model_rnn, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "ahVRO8ZLFFq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model_rnn.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "# fit the model\n",
        "history = model_rnn.fit(X_train, y_train, epochs=350, batch_size=32, verbose=2, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "l1NU-NSvCWUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse, mae = model_rnn.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))"
      ],
      "metadata": {
        "id": "DvFg2ShiB_9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "row = asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps, 1))\n",
        "yhat = model_rnn.predict(row)\n",
        "print('Predicted: %.3f' % (yhat))"
      ],
      "metadata": {
        "id": "NenuIuy1CBl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "XGI92SA4FW07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**<br>\n",
        "Using the California Housing Dataset - create a model for linear regression to predict one of the columns. "
      ],
      "metadata": {
        "id": "_2EdILSXTImS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_df_main = pd.read_csv('/content/sample_data/california_housing_train.csv')"
      ],
      "metadata": {
        "id": "pzFWr0qPUaBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house_df_main.shape"
      ],
      "metadata": {
        "id": "quzrneikU8sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house_df_main.head()"
      ],
      "metadata": {
        "id": "fxqPDRKOU2oV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}