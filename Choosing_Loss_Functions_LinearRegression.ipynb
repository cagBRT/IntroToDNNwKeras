{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Choosing Loss Functions: LinearRegression",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNRtAo2lhdbb5e0qzBngCWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/IntroToDNNwKeras/blob/master/Choosing_Loss_Functions_LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZUuhC5GC1oJ"
      },
      "source": [
        "# **Regression Loss Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7zl-vmhDJLH"
      },
      "source": [
        "This notebook discusses how to choose and implement loss functions for linear regression models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNdmSHKSCrs4"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/IntroToDNNwKeras.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCP11L5wC8K-"
      },
      "source": [
        "Three loss functions will be discussed and implemented in this notebook<br>\n",
        ">Mean Squared Error Loss<br>\n",
        "Mean Squared Logarithmic Error Loss<br>\n",
        "Mean Absolute Error Loss<br>\n",
        "\n",
        "These loss functions can be used when working with CNN and RNN regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXWgZ6j98Wov"
      },
      "source": [
        "**Import the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuhiZKH4DxTa"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6fPCeAzEYlA"
      },
      "source": [
        "#This constant is used in two places\n",
        "#Creating the dataset and in defining the model\n",
        "NUM_FEATURES = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rO7Rr6cDcUU"
      },
      "source": [
        "**Create a synthetic dataset for doing regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TITjFS_mCxUU"
      },
      "source": [
        "# generate regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features= NUM_FEATURES, \n",
        "                       noise=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsNyxUW0D9CU"
      },
      "source": [
        "# normalize the dataset\n",
        "X = StandardScaler().fit_transform(X)\n",
        "y = StandardScaler().fit_transform(y.reshape(len(y),1))[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agFTHakhBF42"
      },
      "source": [
        "**Split the dataset into training and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-2rO0gbEEVN"
      },
      "source": [
        "# split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Ynmn0y8_e-"
      },
      "source": [
        "**The model**<br>\n",
        "The model expects NUM_FEATURES as its input. <br>\n",
        "The model has one hidden layer with 25 nodes and uses the ReLU (rectified linear activation function).<br>\n",
        "The model predicts one value, so the output layer has 1 node and uses the linear activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1eKQWV9EWLI"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=NUM_FEATURES, activation='relu', \n",
        "                kernel_initializer='he_uniform'))\n",
        "#For regression, use one node on the outout and linear activation function\n",
        "model.add(Dense(1, activation='linear'))\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFt0HxAm_-Ru"
      },
      "source": [
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir1e5DQVFmOd"
      },
      "source": [
        "## **Mean Squared Error Loss**<br>\n",
        "This is the default loss to use for regression problems<br>\n",
        "This is the default loss function and should be evaluated first.  \n",
        "*Only change it if you have a good reason*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9dNrwbpCPsF"
      },
      "source": [
        "Mean squared error is the average of the squared differences between the predicted and actual values. <br>\n",
        "*The result is always positive* <br>\n",
        "A perfect value is 0.0.<br>\n",
        "Squaring the losses results in larger mistakes creating more error than smaller mistakes. <br>\n",
        "In other words, **the model is punished for larger mistakes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uieJgmnKEtt0"
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=opt,metrics=['mse'])\n",
        "# train the model\n",
        "historyMSE = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                       epochs=400, verbose=0,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1LeTw_sG_-v"
      },
      "source": [
        "# evaluate the model\n",
        "_,train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
        "_,test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2opobHcoKKb2"
      },
      "source": [
        "# plot loss during training\n",
        "pyplot.title('Loss / Mean Squared Error')\n",
        "pyplot.plot(historyMSE.history['loss'], label='train')\n",
        "pyplot.plot(historyMSE.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFP04xM6DZrL"
      },
      "source": [
        "The model quickly converged and the training and tests performance are equal. <br>\n",
        "It is fair to say MSE is a good choice for this data and model.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHtorsiOFzY4"
      },
      "source": [
        "## **Mean Squared Logarithmic Error Loss**<br>\n",
        "MSLE is used when the target value has a spread of values and when predicting large values.<br>\n",
        "MSLE does not punish the model has much as MSE for errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmwSLmz3EgPv"
      },
      "source": [
        "MSLE first calculates the log of each predicted value. <br>\n",
        "The calculates the mean squared error<br>\n",
        "This reduces the effect of large differences when the predicted values are large. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2sfsQt_L5H6"
      },
      "source": [
        "#The model is the same as above\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu', \n",
        "                kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvEiB0TrJumM"
      },
      "source": [
        "The metrics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJIk3ud1Fyj9"
      },
      "source": [
        "model.compile(loss='mean_squared_logarithmic_error', optimizer=opt,\n",
        "              metrics=['msle'])\n",
        "# fit model\n",
        "historyMSLE = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                        epochs=400, verbose=0,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzDNGqj6G7WW"
      },
      "source": [
        "# evaluate the model\n",
        "_,train_msle = model.evaluate(X_train, y_train, verbose=0)\n",
        "_,test_msle = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_msle, test_msle))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP71Gp_kKMhR"
      },
      "source": [
        "# plot loss during training\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Loss / Mean Squared Logarithmic Error')\n",
        "pyplot.plot(historyMSLE.history['loss'], label='train')\n",
        "pyplot.plot(historyMSLE.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot mse during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Mean Squared Error')\n",
        "pyplot.plot(historyMSE.history['loss'], label='train')\n",
        "pyplot.plot(historyMSE.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lduIkATOLKb4"
      },
      "source": [
        "The model has a greater loss difference between the training and test set. <br>\n",
        "It also stopped training at 13 epochs, so it tends to overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L59M78a5GNo5"
      },
      "source": [
        "## **Mean Absolute Error Loss**<br>\n",
        "Use the Mean Absolute Error Loss when the dataset has outliers. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-XG1r21LjU3"
      },
      "source": [
        "#The same model as the MSE\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu', \n",
        "                kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvSFa0t3GN6G"
      },
      "source": [
        "model.compile(loss='mean_absolute_error', optimizer=opt, metrics=['mse'])\n",
        "# fit model\n",
        "historyMAE = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
        "                       epochs=400, verbose=0,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edvzwvUuFP3d"
      },
      "source": [
        "# evaluate the model\n",
        "_,train_mae = model.evaluate(X_train, y_train, verbose=0)\n",
        "_,test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGfKtO5fFL2a"
      },
      "source": [
        "# plot loss during training\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Mean Absolute Error Loss')\n",
        "pyplot.plot(historyMAE.history['loss'], label='train')\n",
        "pyplot.plot(historyMAE.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot mse during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Mean Squared Error')\n",
        "pyplot.plot(historyMSE.history['loss'], label='train')\n",
        "pyplot.plot(historyMSE.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}