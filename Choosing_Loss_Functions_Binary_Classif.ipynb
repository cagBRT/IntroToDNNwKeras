{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Choosing Loss Functions: Binary Classif.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOzgA5kzNlf28OSvhoTLwhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/IntroToDNNwKeras/blob/master/Choosing_Loss_Functions_Binary_Classif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A loss function is incredibly simple: It’s a method of evaluating how well your algorithm models your dataset. If your predictions are totally off, your loss function will output a higher number. If they’re pretty good, it’ll output a lower number. As you change pieces of your algorithm to try and improve your model, your loss function will tell you if you’re getting anywhere."
      ],
      "metadata": {
        "id": "imuxQ82e4q1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss functions are related to model accuracy"
      ],
      "metadata": {
        "id": "ptbwIyAf47Xr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9e2kP5rPJPz"
      },
      "source": [
        "# **Coosing Loss Functions for Binary Classification**<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFz8Nb6_PMgJ"
      },
      "source": [
        "This notebook looks at three loss functions used in binary classification<br>\n",
        ">Binary Cross-Entropy Loss<br>\n",
        "Hinge Loss<br>\n",
        "Squared Hinge Loss<br>\n",
        "\n",
        "Synthetic data consisting of two classes is used in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvrSwpg4jNSC"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE70sodUN7Sn"
      },
      "source": [
        "# mlp for the circles problem with cross entropy loss\n",
        "from sklearn.datasets import make_circles\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from numpy import where\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI1SqPadjnLG"
      },
      "source": [
        "**Create the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHrljva0NVxd"
      },
      "source": [
        "# generate circles\n",
        "X, y = make_circles(n_samples=1000, noise=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeHFMumdNcdr"
      },
      "source": [
        "# scatter plot of the circles dataset \n",
        "# select indices of points with each class label\n",
        "for i in range(2):\n",
        "\tsamples_ix = where(y == i)\n",
        "\tpyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plTxkvWskF6w"
      },
      "source": [
        "The data ranges from -1 to 1 so it does not need to be normalized for this dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IVIMKjSNjK1"
      },
      "source": [
        "# split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duQiYUKnkyxc"
      },
      "source": [
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxPEHzYuPaFJ"
      },
      "source": [
        "## **Binary Cross-Entropy Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAEoDL88l4ly"
      },
      "source": [
        "**The model**<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ5Wr7UYNqaV"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grgON4TyORKj"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjfN-3lfOV3G"
      },
      "source": [
        "# fit model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
        "                    epochs=200, verbose=0,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwatBpUkOaNZ"
      },
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9faNRImQOfSW"
      },
      "source": [
        "# plot loss during training\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot accuracy during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmbujRNCPfAF"
      },
      "source": [
        "**Hinge Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgA_lj7HPhyC"
      },
      "source": [
        "from numpy import where"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFx5ZUKSPpcP"
      },
      "source": [
        "# generate 2d classification dataset\n",
        "\n",
        "# generate circles\n",
        "X, y = make_circles(n_samples=1000, noise=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot of the circles dataset \n",
        "# select indices of points with each class label\n",
        "for i in range(2):\n",
        "\tsamples_ix = where(y == i)\n",
        "\tpyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "lDAdAwb9i2S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw3_W0_RPzEl"
      },
      "source": [
        "# split into train and test\n",
        "n_train = 500\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt-gUwiCP2W-"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='tanh'))\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(loss='hinge', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUeM0PHBP8sZ"
      },
      "source": [
        "# fit model\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3rZc3r4QAtA"
      },
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iir05hhQEu3"
      },
      "source": [
        "# plot loss during training\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot accuracy during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZikDOK1RY7L"
      },
      "source": [
        "**Squared Hinge Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EumupicyRcId"
      },
      "source": [
        "# generate circles\n",
        "X, y = make_circles(n_samples=1000, noise=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot of the circles dataset \n",
        "# select indices of points with each class label\n",
        "for i in range(2):\n",
        "\tsamples_ix = where(y == i)\n",
        "\tpyplot.scatter(X[samples_ix, 0], X[samples_ix, 1], label=str(i))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "rCCApLgJjR89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVNUufGKR6Qj"
      },
      "source": [
        "# split into train and test\n",
        "n_train = 500\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aKNPVzKR-Az"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='tanh'))\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='squared_hinge', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoZ8yOazSDNe"
      },
      "source": [
        "# fit model\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaGHytWeSGAQ"
      },
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDYOnqU2SKPP"
      },
      "source": [
        "# plot loss during training\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot accuracy during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}